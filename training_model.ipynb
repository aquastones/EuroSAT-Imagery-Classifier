{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43c9d03-3e96-42b8-b0a3-fd446937708d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1><strong>PyTorch Fundamentals -- My Notes</strong></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3f473",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce0106-0f8a-401a-b415-bd69dd582baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn # Neural network module with loss functions, layers and container modules\n",
    "from torch.utils.data import DataLoader # Load and batch data using this\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # Scheduler\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "\n",
    "from torchvision.datasets import ImageFolder # to use custom datasets\n",
    "from torchvision import transforms # get functions for manipulating your vision data here\n",
    "from torchvision.transforms import ToTensor # convert a PIL image of numpy array to tensor using this\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other imports\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Check versions\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"\\nCUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpu = torch.cuda.get_device_name(0)\n",
    "print(f\"GPU: {gpu}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bdf0c-446d-48a4-ab92-1f127c641c06",
   "metadata": {},
   "source": [
    "### Vast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eed820-79fa-4a59-9cfd-29cf8bb3e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# import zipfile\n",
    "\n",
    "# zip_path = r\"EuroSATsplit.zip\"\n",
    "# extract_path = r\"data/EuroSATsplit\"\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "#     zip_ref.extractall(extract_path)\n",
    "\n",
    "# print(os.listdir(extract_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672e8b6",
   "metadata": {},
   "source": [
    "### Data transformation & Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e80e23-e7f9-4281-a4f3-0f5a33c26159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3444, 0.3803, 0.4078], std=[0.2027, 0.1369, 0.1155])\n",
    "])\n",
    "\n",
    "# Define paths\n",
    "TRAIN_PATH = r\"data/EuroSATsplit/train\"\n",
    "TEST_PATH = r\"data/EuroSATsplit/test\"\n",
    "\n",
    "# Load a custom dataset\n",
    "train_data = ImageFolder(root=TRAIN_PATH, transform=transform)\n",
    "test_data = ImageFolder(root=TEST_PATH, transform=transform)\n",
    "\n",
    "# See what the dataset looks like\n",
    "class_names = train_data.classes\n",
    "class_len = len(train_data.classes)\n",
    "train_len = len(train_data)\n",
    "test_len = len(test_data)\n",
    "print(f\"Train data length: {train_len}\\nTest data length: {test_len}\\n\\nClass names ({class_len}): {class_names}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b7e5c-7b3a-4174-9844-bae2cc4221c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into batches\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Inspect data\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "print(f\"\\nShape of train_features_batch: {train_features_batch.shape}\\n-> [batch_size, color_channels, height, width]\")\n",
    "print(f\"\\nShape of train_labels_batch: {train_labels_batch.shape}\\n-> [batch_size]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda9f403",
   "metadata": {},
   "source": [
    "### Show 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef60ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ids = torch.randint(0, len(train_features_batch), size=[5]).tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "for i, idx in enumerate(rand_ids):\n",
    "    img, label = train_features_batch[idx], train_labels_batch[idx]\n",
    "\n",
    "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
    "    axes[i].set_title(class_names[label])\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67adc9",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a40547",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542ef2c-6ec6-485b-b780-9c65d15ce001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a baseline model\n",
    "# class BreedIDModel(nn.Module):\n",
    "#     def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "#         super().__init__()\n",
    "#         self.layer_stack = nn.Sequential(nn.Flatten(),\n",
    "#                                          nn.Linear(in_features=input_shape,\n",
    "#                                                    out_features=hidden_units),\n",
    "#                                          nn.Linear(in_features=hidden_units,\n",
    "#                                                    out_features=output_shape))\n",
    "#     def forward(self, x):\n",
    "#         return self.layer_stack(x)\n",
    "\n",
    "# # See what the model looks like\n",
    "# h = 224\n",
    "# w = 224\n",
    "# c = 1\n",
    "# model = BreedIDModel(input_shape=h*w*c,\n",
    "#                          hidden_units=10,\n",
    "#                          output_shape=len(class_names))\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b590eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load EfficientNet model\n",
    "# model = torchvision.models.efficientnet_b0(weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT).to(device)\n",
    "\n",
    "# # Parameter training setting\n",
    "# for param in model.features.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # Define classifier\n",
    "# model.classifier = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(in_features=model.classifier[1].in_features,\n",
    "#                     out_features=class_len,\n",
    "#                     bias=True)\n",
    "#                     ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3d4b1",
   "metadata": {},
   "source": [
    "#### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DenseNet model\n",
    "model = torchvision.models.densenet169(weights=torchvision.models.DenseNet169_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Parameter training setting\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Define classifier\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=model.classifier.in_features,\n",
    "                    out_features=class_len,\n",
    "                    bias=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d982ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Move model to device and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d871843",
   "metadata": {},
   "source": [
    "### Initialize Accuracy Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ef116-ce8f-49fd-9690-de18cba310a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "# Setup loss function, optimizer and scheduler\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c6b7f",
   "metadata": {},
   "source": [
    "### Define colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80351cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI color codes\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "CYAN = \"\\033[96m\"\n",
    "RESET = \"\\033[0m\"  # Reset color\n",
    "\n",
    "# Define color variations\n",
    "MODEL_COLOR = CYAN if model._get_name == \"EfficientNet\" else BLUE\n",
    "PARAM_COLOR = GREEN if param.requires_grad else RED\n",
    "BATCH_COLOR = RED if BATCH_SIZE >= 64 else YELLOW\n",
    "GPU_COLOR = GREEN if device == 'cuda' else RED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f045a236",
   "metadata": {},
   "source": [
    "### Define logging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(filenames):\n",
    "    for filename in filenames:\n",
    "        with open(f\"csv/{filename}.csv\", \"w\"): pass\n",
    "\n",
    "def log_csv(filename, data):\n",
    "    with open(f\"csv/{filename}.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d3fde",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4fc13-4cf5-4c2e-8a3f-a1a9402f746f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directories for outputs\n",
    "dirs = [\"csv\", \"txt\", \"confusion-matrices\", \"roc-curves\", \"models\"]\n",
    "for dir in dirs:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Clean csv's\n",
    "clean_csv([\"accuracy\", \"train_loss\", \"test_loss\"])\n",
    "\n",
    "# Print training info\n",
    "print(f\"TRAINING {MODEL_COLOR}{model._get_name()}{RESET}\\n\"\n",
    "      f\"PARAMETER TRAINING {PARAM_COLOR}{param.requires_grad}{RESET}\\n\"\n",
    "      f\"BATCHES OF {BATCH_COLOR}{BATCH_SIZE}{RESET}\\n\"\n",
    "      f\"ON {GPU_COLOR}{gpu}{RESET}\\n\")\n",
    "\n",
    "# Set num of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, epochs+1):\n",
    "    # Reset timer\n",
    "    start_time = timer()\n",
    "\n",
    "    # Reset train loss\n",
    "    train_loss, best_acc = 0, 0\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    # X - image, y - label\n",
    "    for batch, (X, y) in enumerate(train_dataloader, start=1):\n",
    "        # Move data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calc loss per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Zero grad the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Output progress\n",
    "        if batch % 10 == 0 or batch == len(train_dataloader):\n",
    "            end_time = timer()\n",
    "            total_time = end_time - start_time\n",
    "            samples = batch * len(X)\n",
    "            total_samples = len(train_dataloader.dataset)\n",
    "            seconds_per_batch = total_time / batch\n",
    "            eta = max(0, (len(train_dataloader) - batch) * seconds_per_batch)\n",
    "            eta_h = int(eta // 3600)\n",
    "            eta_m = int((eta % 3600) // 60)\n",
    "            eta_s = int(eta % 60)\n",
    "            print(f\"{CYAN}Epoch {epoch}:{RESET} looked at {GREEN}{samples}/{total_samples}{RESET} samples \"\n",
    "                    f\"({YELLOW}{total_time:.2f}{RESET} seconds taken, {BLUE}{seconds_per_batch:.2f}{RESET} s/batch, \"\n",
    "                    f\"ETA: {RED}{eta_h}h{RESET} {GREEN}{eta_m}m{RESET} {BLUE}{eta_s}s{RESET})\", end=\"\\r\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Reset test loss and acc\n",
    "    test_loss, total_samples, total_correct = 0, 0, 0\n",
    "    predictions, labels = [], []\n",
    "    roc_labels, roc_probabilities = [], []\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Testing loop\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            # Move data to device\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X_test)\n",
    "\n",
    "            # Calculate ROC-curve data\n",
    "            probabilities = torch.softmax(test_pred, dim=1)  # Shape: (batch_size, num_classes)\n",
    "            roc_labels.extend(y_test.cpu().numpy())  # True labels\n",
    "            roc_probabilities.extend(probabilities.cpu().numpy())  # Probabilities for all classes\n",
    "\n",
    "            # 2. Calculate loss\n",
    "            test_loss += loss_fn(test_pred, y_test).item()\n",
    "\n",
    "            # 3. Count correct predictions\n",
    "            correct_predictions = torch.eq(y_test, test_pred.argmax(dim=1)).sum().item()\n",
    "            total_correct += correct_predictions\n",
    "            total_samples += len(y_test)\n",
    "\n",
    "            # 4. Store predictions and labels for confusion matrix\n",
    "            predictions.extend(test_pred.argmax(dim=1).cpu().numpy())\n",
    "            labels.extend(y_test.cpu().numpy())\n",
    "\n",
    "        # 5. Calc test loss avg per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc = (total_correct / total_samples)\n",
    "\n",
    "    # Save best weights\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), f\"models/{model._get_name()}_{param.requires_grad}_{(test_acc*100):.2f}_weights.pt\")\n",
    "\n",
    "    # Update scheduler\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    # Print & Log results\n",
    "    print(f\"\\nTrain loss = {train_loss:.2f}\\nTest loss = {test_loss:.2f}\\nTest accuracy = {GREEN}{(test_acc*100):.2f}%{RESET}\\n\")\n",
    "    log_csv(\"accuracy\", [epoch, round(test_acc, 4)])\n",
    "    log_csv(\"train_loss\", [epoch, round(train_loss, 2)])\n",
    "    log_csv(\"test_loss\", [epoch, round(test_loss, 2)])\n",
    "\n",
    "    # Compute confusion matrix and save it\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    np.save(f\"confusion-matrices/cm{epoch}.npy\", cm)\n",
    "\n",
    "    # Convert to numpy arrays and save ROC-curve data\n",
    "    roc_labels = np.array(roc_labels)\n",
    "    roc_probabilities = np.array(roc_probabilities)\n",
    "    np.save(f\"roc-curves/roc_labels{epoch}.npy\", roc_labels)\n",
    "    np.save(f\"roc-curves/roc_probabilities{epoch}.npy\", roc_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
